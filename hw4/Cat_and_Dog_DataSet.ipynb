{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VdZCXzHt468r"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#import requried library\n",
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Download the data set and unzip it\n",
        "!wget --no-check-certificate https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Set up the cat and dog training and validation directories\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat and dog pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat and dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "# Verify the first 10 frams name of cat and dog list \n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_cat_fnames.sort()\n",
        "print(train_cat_fnames[:10])\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "train_dog_fnames.sort()\n",
        "print(train_dog_fnames[:10])\n",
        "\n",
        "# Print the total number of cat and dog images in training and validation directories\n",
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "\n",
        "# Let's look at some of the images\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "pic_index=0\n",
        "\n",
        "# Set up matplotlib fig. and size it to fit 4X4 pics\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "pic_index+=8\n",
        "next_cat_pix=[os.path.join(train_cats_dir, fname)\n",
        "    for fname in train_cat_fnames[pic_index-8:pic_index]\n",
        "    ]\n",
        "next_dog_pix=[os.path.join(train_dogs_dir, fname)\n",
        "    for fname in train_dog_fnames[pic_index-8:pic_index]\n",
        "    ]\n",
        "  \n",
        "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
        "# Set up subplot; subplot indices start at 1\n",
        "  sp= plt.subplot(nrows, ncols, i+1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img= mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Building a model\n",
        "\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "model = models.Sequential([\n",
        "\t# Note that the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "\tlayers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "\tlayers.MaxPooling2D(2,2),\n",
        "\tlayers.Conv2D(32, (3,3), activation='relu'),\n",
        "\tlayers.MaxPooling2D(2,2),\n",
        "\tlayers.Conv2D(64, (3,3), activation='relu'),\n",
        "\tlayers.MaxPooling2D(2,2),\n",
        "\t# Flatten the results to feed into a DNN\n",
        "\tlayers.Flatten(),\n",
        "\t# 512 neuron hidden layer\n",
        "\tlayers.Dense(512, activation='relu'),\n",
        "\t# Only 1 ouput neuron. It will contain a value from 0-1, 0 for cat class and 1 for dog class\n",
        "\tlayers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile model\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "\t\t\tloss='binary_crossentropy',\n",
        "\t\t\tmetrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GKd1eA3hI9YJ"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255.\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "# ----------\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "# ----------\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "\t\t\t\t\t\t\t\t\t\t\tbatch_size=20,\n",
        "\t\t\t\t\t\t\t\t\t\t\tclass_mode='binary',\n",
        "\t\t\t\t\t\t\t\t\t\t\ttarget_size=(150,150))\n",
        "\n",
        "# ----------\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "# ----------\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "\t\t\t\t\t\t\t\t\t\t\tbatch_size=20,\n",
        "\t\t\t\t\t\t\t\t\t\t\tclass_mode='binary',\n",
        "\t\t\t\t\t\t\t\t\t\t\ttarget_size=(150,150))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "\t\t\t\t\t\tvalidation_data=validation_generator,\n",
        "\t\t\t\t\t\tsteps_per_epoch=100,\n",
        "\t\t\t\t\t\tepochs=15,\n",
        "\t\t\t\t\t\tvalidation_steps=50,\n",
        "\t\t\t\t\t\tverbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Running the model\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\t# Predicting images\n",
        "\tpath = '/content/' + fn\n",
        "\timg = image.load_img(path, target_size=(150, 150))\n",
        "\n",
        "\tx = image.img_to_array(img)\n",
        "\tx = np.expand_dims(x, axis=0)\n",
        "\timages = np.vstack([x])\n",
        "\n",
        "\tclasses = model.predict(images, batch_size=10)\n",
        "\n",
        "\tprint(classes[0])\n",
        "\n",
        "\tif classes[0] > 0:\n",
        "\t\tprint(fn + \" is a dog\")\n",
        "\telse:\n",
        "\t\tprint(fn + \" is a cat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizing Intermediate Representations\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "\n",
        "#visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(\n",
        "    inputs=model.input, outputs=successive_outputs)\n",
        "\n",
        "# Let's prepare a random input image of a cat or dog from the training set.\n",
        "cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\n",
        "dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n",
        "\n",
        "img_path = random.choice(cat_img_files + dog_img_files)\n",
        "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
        "\n",
        "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255.0\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Now let's display our representations\n",
        "# -----------------------------------------------------------------------\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "\tif len(feature_map.shape) == 4:\n",
        "\t\t# -------------------------------------------\n",
        "\t\t# Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "\t\t# -------------------------------------------\n",
        "\t\t# number of features in the feature map\n",
        "\t\tn_features = feature_map.shape[-1]\n",
        "\t\t# feature map shape (1, size, size, n_features)\n",
        "\t\tsize = feature_map.shape[1]\n",
        "\n",
        "\t\t# We will tile our images in this matrix\n",
        "\t\tdisplay_grid = np.zeros((size, size * n_features))\n",
        "\n",
        "\t\t# -------------------------------------------------\n",
        "\t\t# Postprocess the feature to be visually palatable\n",
        "\t\t# -------------------------------------------------\n",
        "\t\tfor i in range(n_features):\n",
        "\t\t\tx = feature_map[0, :, :, i]\n",
        "\t\t\tx -= x.mean()\n",
        "\t\t\tx /= x.std()\n",
        "\t\t\tx *= 64\n",
        "\t\t\tx += 128\n",
        "\t\t\tx = np.clip(x, 0, 255).astype('uint8')\n",
        "\t\t\t# Tile each filter into a horizontal grid\n",
        "\t\t\tdisplay_grid[:, i * size: (i + 1) * size] = x\n",
        "\t\t# -----------------\n",
        "\t\t# Display the grid\n",
        "\t\t# -----------------\n",
        "\t\tscale = 20. / n_features\n",
        "\t\tplt.figure(figsize=(scale * n_features, scale))\n",
        "\t\tplt.title(layer_name)\n",
        "\t\tplt.grid(False)\n",
        "\t\tplt.imshow(display_grid, aspect='auto', cmap='viridis')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.title('Training and validation loss')\n",
        "plt.figure()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
