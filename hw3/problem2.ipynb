{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  Europe  Japan  USA  \n",
       "393          82       0      0    1  \n",
       "394          82       1      0    0  \n",
       "395          82       0      0    1  \n",
       "396          82       0      0    1  \n",
       "397          82       0      0    1  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]], dtype=float)\n",
    "# y = np.array([[0.0], [0.0], [0.0], [1.0]], dtype=float)\n",
    "\n",
    "#  input x\n",
    "# x = np.random.uniform(-.5,.5,size=(100,3))\n",
    "# y = np.random.uniform(-.5,.5,size=(100,1))\n",
    "# for i in range(0,50):\n",
    "#     x[i,2] = 1\n",
    "#     y[i,0] = 0\n",
    "\n",
    "# # x1, x2 between two circles with radius 3 and 4, x3 = 1\n",
    "# for i in range(50,100):\n",
    "#     r = np.random.uniform(3.0, 4)\n",
    "#     theta = np.random.uniform(0.0,1) * 2 * math.pi\n",
    "#     x[i,0] = r * np.cos(theta)\n",
    "#     x[i,1] = r * np.sin(theta)\n",
    "#     x[i,2] = 1\n",
    "#     y[i,0] = 1\n",
    "\n",
    "# Used the following walkthrough from Tensorflow Documentation to learn how to use the dataset for training\n",
    "# https://www.tensorflow.org/tutorials/keras/regression\n",
    "\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "dataset = pandas.read_csv(\"data/auto-mpg.data\", names=column_names,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True).copy().dropna()\n",
    "\n",
    "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset = pandas.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')\n",
    "dataset.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.47770691e+00 1.95318497e+02 1.04869446e+02 2.99025195e+03\n",
      "  1.55592356e+01 7.58980942e+01 1.78343967e-01 1.97452217e-01\n",
      "  6.24203861e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 16:53:56.542716: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-14 16:53:56.553448: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "training_data = dataset.sample(frac=0.8, random_state=0)\n",
    "test_data = dataset.drop(training_data.index)\n",
    "\n",
    "training_features = training_data.copy()\n",
    "test_features = test_data.copy()\n",
    "\n",
    "training_labels = training_features.pop('MPG')\n",
    "test_labels = test_data.pop('MPG')\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(training_features))\n",
    "\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 16:53:56.675778: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-14 16:53:56.687227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "horsepower = np.array(training_features['Horsepower'])\n",
    "\n",
    "horsepower_normalizer = keras.layers.Normalization(input_shape=[1,], axis=None)\n",
    "horsepower_normalizer.adapt(horsepower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_42 (Normaliza  (None, 9)                19        \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29\n",
      "Trainable params: 10\n",
      "Non-trainable params: 19\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#    keras.layers.Dense(units=1, input_shape=[2], activation=tf.nn.relu)])\n",
    "# model = tf.keras.Sequential([\n",
    "#   keras.layers.Dense(units=4, input_shape=[None,3], activation=tf.nn.relu),\n",
    "# keras.layers.Dense(units=5, activation=tf.nn.relu),\n",
    "# keras.layers.Dense(units=1, activation=tf.nn.sigmoid)])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  normalizer,\n",
    "  keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 16:53:56.847058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.6832452 ],\n",
       "       [-0.09856419],\n",
       "       [ 1.914506  ],\n",
       "       [-2.0366998 ],\n",
       "       [-1.5918509 ],\n",
       "       [ 0.05634813],\n",
       "       [-1.7655438 ],\n",
       "       [ 1.7616717 ],\n",
       "       [-0.13857298],\n",
       "       [-0.65949595]], dtype=float32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model.predict(training_features[:10])\n",
    "model.predict(np.asarray(training_features[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 22.9419 - val_loss: 22.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 16:53:57.084273: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-14 16:53:57.239338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 22.0850 - val_loss: 22.1271\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 21.2724 - val_loss: 21.3820\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 20.4518 - val_loss: 20.6539\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 19.6505 - val_loss: 19.9463\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 18.8096 - val_loss: 19.2075\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 17.9844 - val_loss: 18.4728\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 17.1922 - val_loss: 17.7502\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 16.3798 - val_loss: 17.0191\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 15.5597 - val_loss: 16.2939\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 14.7817 - val_loss: 15.5712\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 13.9447 - val_loss: 14.8412\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 13.1328 - val_loss: 14.1193\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12.3499 - val_loss: 13.4554\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.5014 - val_loss: 12.6768\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.7649 - val_loss: 11.9067\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.9095 - val_loss: 11.2244\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.1231 - val_loss: 10.5308\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.3799 - val_loss: 9.7448\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.6522 - val_loss: 9.0795\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.9767 - val_loss: 8.3374\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.3627 - val_loss: 7.6582\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.7668 - val_loss: 7.0786\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.2624 - val_loss: 6.6503\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.7889 - val_loss: 5.8828\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.3680 - val_loss: 5.0733\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.9197 - val_loss: 4.4785\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.4859 - val_loss: 3.8186\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.1357 - val_loss: 3.4252\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.9250 - val_loss: 3.0134\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.7655 - val_loss: 2.8427\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6600 - val_loss: 2.7941\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6661 - val_loss: 2.6297\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.5330 - val_loss: 2.6910\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.5261 - val_loss: 2.6074\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.4989 - val_loss: 2.5799\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.4948 - val_loss: 2.5803\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4906 - val_loss: 2.5131\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4734 - val_loss: 2.5038\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4775 - val_loss: 2.4838\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4879 - val_loss: 2.4903\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4720 - val_loss: 2.4866\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.4805 - val_loss: 2.4950\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.4768 - val_loss: 2.4635\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.4850 - val_loss: 2.4931\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.4824 - val_loss: 2.4651\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.5139 - val_loss: 2.4731\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4851 - val_loss: 2.4860\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4776 - val_loss: 2.4639\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4901 - val_loss: 2.5527\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4710 - val_loss: 2.4989\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.4829 - val_loss: 2.4993\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.4914 - val_loss: 2.4726\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.5195 - val_loss: 2.4792\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.4935 - val_loss: 2.4588\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.4924 - val_loss: 2.4646\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4663 - val_loss: 2.5221\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4989 - val_loss: 2.4839\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4762 - val_loss: 2.5262\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4865 - val_loss: 2.4914\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4866 - val_loss: 2.5309\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5098 - val_loss: 2.4851\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4629 - val_loss: 2.5002\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4837 - val_loss: 2.4607\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4795 - val_loss: 2.5015\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4915 - val_loss: 2.4592\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4832 - val_loss: 2.4914\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4810 - val_loss: 2.4582\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4924 - val_loss: 2.5084\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4782 - val_loss: 2.4488\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4816 - val_loss: 2.4933\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4828 - val_loss: 2.4884\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4805 - val_loss: 2.4544\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4847 - val_loss: 2.5095\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5041 - val_loss: 2.4658\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4986 - val_loss: 2.5007\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4735 - val_loss: 2.4604\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4875 - val_loss: 2.4851\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4788 - val_loss: 2.4527\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4729 - val_loss: 2.4543\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4677 - val_loss: 2.4899\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4815 - val_loss: 2.4716\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4744 - val_loss: 2.4733\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5282 - val_loss: 2.4641\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4872 - val_loss: 2.4595\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4720 - val_loss: 2.4603\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4800 - val_loss: 2.4712\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4707 - val_loss: 2.4800\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4730 - val_loss: 2.4670\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4915 - val_loss: 2.4733\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4968 - val_loss: 2.4672\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4865 - val_loss: 2.4567\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4714 - val_loss: 2.4940\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4743 - val_loss: 2.4672\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4706 - val_loss: 2.5325\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4670 - val_loss: 2.4734\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4694 - val_loss: 2.4951\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.4792 - val_loss: 2.4589\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4959 - val_loss: 2.4719\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.4747 - val_loss: 2.4611\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    np.asarray(training_features),\n",
    "    np.asarray(training_labels),\n",
    "    epochs=100,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26.077099]\n",
      " [24.636162]\n",
      " [12.188329]\n",
      " [31.114946]\n",
      " [32.52069 ]\n",
      " [22.354626]\n",
      " [33.224373]\n",
      " [24.756727]\n",
      " [20.492535]\n",
      " [26.846601]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 16:54:02.762991: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.asarray(training_features[:10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Error')\n",
    "\n",
    "plt.title('Loss Curve')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21a601794a7cd45889532e042ab1191391bed29783ca1b1cad2908006cea832d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('cps584': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
